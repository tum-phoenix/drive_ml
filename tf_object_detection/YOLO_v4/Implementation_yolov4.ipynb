{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0j9ROzCBOUY"
      },
      "source": [
        "# YOLOv4 Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B6DJ0BS-86O"
      },
      "source": [
        "The goal of this notebook is the implementation of the YOLOv4 neuronal network for sign detection. For that, an installation and use of DarkNet Framework on Ubuntu (18.04) will be introduced. Then, the setup of the darknet repository will be modified depending on the nature of our specific goal and corresponding dataset. After that, the neural network will be trained on the German Traffic Sign Detection Benchmark (GTSDB) Dataset, then the best weights will be used to detect signs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBC-SJ-aLk2p"
      },
      "source": [
        "## Installation & Use DarkNet FRamework on UBuntu 18.04 (LTS)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FE7seDZL2ED"
      },
      "source": [
        "Source: https://medium.com/@pavan.mksolution/installation-use-darknet-framework-on-ubuntu-18-04-lts-f90ac3041fed\r\n",
        "\r\n",
        "Follow below steps for Installation :\r\n",
        "1. Create your working directory as any name you can give.\r\n",
        "2. Open Terminal and type command [sudo apt-get install git]\r\n",
        "3. copy this command from the website : https://github.com/AlexeyAB/darknet.git\r\n",
        "\r\n",
        "How to Use :\r\n",
        "\r\n",
        "These are steps for CPU computation, just to check how our output will look like !\r\n",
        "Once you clone the darknet to your directory (DarkNet Folder — root)\r\n",
        "1. Open command prompt and run : `$ cd darknet`\r\n",
        "2. Make the folder by running : `$ make`\r\n",
        "3. Download Pre-Trained Model & simply copy it into your working directory (i.e darknet)\r\n",
        "`!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137`\r\n",
        "4. TEST : Run the command\r\n",
        "`./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHIJ-0CyPjLd"
      },
      "source": [
        "## Modify the yolov4 repository "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow_ZyxFvCHmb"
      },
      "source": [
        "Source: https://medium.com/ai-world/how-to-train-yolov4-for-custom-objects-detection-in-google-colab-1e934b8ef685\r\n",
        "\r\n",
        "Now we have to make some changes to adapt the yolov4 file to the nature of the GTSDB dataset.\r\n",
        "\r\n",
        "1. Open darknet-master folder which we have just downloaded and from that open cfg folder now in the cfg folder make a copy of the file yolo4-custom.cfg now rename the copy file to yolo-obj.cfg\r\n",
        "    \r\n",
        "    a. open the file yolo-obj.cfg and change max_batches to (classes*2000),if you have 6 object classes change max_batches=12000.\r\n",
        "\r\n",
        "    b. Then change the line steps to (0.8*max_batches ,0.9*max_batches) ie; if you have 6 classes steps=9600,10800.\r\n",
        "\r\n",
        "    c. set network size width=416 height=416\r\n",
        "\r\n",
        "    d. change line classes=80 to your number of objects in each of 3 yolo layers.\r\n",
        "\r\n",
        "    e. change [filters=255] to filters=(classes + 5)x3 in the 3 convolutional layer immediately before each 3 yolo layers.If you have 6 classes filters=33\r\n",
        "2. Download the pre trained weights from the link [yolov4.conv.137](https://drive.google.com/file/d/1JKF-bdIklxOOVy-2Cr5qdvjgGpmGfcbp/view) and save it in the darknet-master folder\r\n",
        "\r\n",
        "3. Open wordpad and type the name of each object in separate lines and save the file as obj.names in darknet-master->data folder\r\n",
        "\r\n",
        "0 = speed limit 20 (prohibitory)\r\n",
        "\r\n",
        "1 = speed limit 30 (prohibitory)\r\n",
        "\r\n",
        "2 = speed limit 50 (prohibitory)\r\n",
        "\r\n",
        "3 = speed limit 60 (prohibitory)\r\n",
        "\r\n",
        "4 = speed limit 70 (prohibitory)\r\n",
        "\r\n",
        "5 = speed limit 80 (prohibitory)\r\n",
        "\r\n",
        "6 = restriction ends 80 (other)\r\n",
        "\r\n",
        "7 = speed limit 100 (prohibitory)\r\n",
        "\r\n",
        "8 = speed limit 120 (prohibitory)\r\n",
        "\r\n",
        "9 = no overtaking (prohibitory)\r\n",
        "\r\n",
        "10 = no overtaking (trucks) (prohibitory)\r\n",
        "\r\n",
        "11 = priority at next intersection (danger)\r\n",
        "\r\n",
        "12 = priority road (other)\r\n",
        "\r\n",
        "13 = give way (other)\r\n",
        "\r\n",
        "14 = stop (other)\r\n",
        "\r\n",
        "15 = no traffic both ways (prohibitory)\r\n",
        "\r\n",
        "16 = no trucks (prohibitory)\r\n",
        "\r\n",
        "17 = no entry (other)\r\n",
        "\r\n",
        "18 = danger (danger)\r\n",
        "\r\n",
        "19 = bend left (danger)\r\n",
        "\r\n",
        "20 = bend right (danger)\r\n",
        "\r\n",
        "21 = bend (danger)\r\n",
        "\r\n",
        "22 = uneven road (danger)\r\n",
        "\r\n",
        "23 = slippery road (danger)\r\n",
        "\r\n",
        "24 = road narrows (danger)\r\n",
        "\r\n",
        "25 = construction (danger)\r\n",
        "\r\n",
        "26 = traffic signal (danger)\r\n",
        "\r\n",
        "27 = pedestrian crossing (danger)\r\n",
        "\r\n",
        "28 = school crossing (danger)\r\n",
        "\r\n",
        "29 = cycles crossing (danger)\r\n",
        "\r\n",
        "30 = snow (danger)\r\n",
        "\r\n",
        "31 = animals (danger)\r\n",
        "\r\n",
        "32 = restriction ends (other)\r\n",
        "\r\n",
        "33 = go right (mandatory)\r\n",
        "\r\n",
        "34 = go left (mandatory)\r\n",
        "\r\n",
        "35 = go straight (mandatory)\r\n",
        "\r\n",
        "36 = go right or straight (mandatory)\r\n",
        "\r\n",
        "37 = go left or straight (mandatory)\r\n",
        "\r\n",
        "38 = keep right (mandatory)\r\n",
        "\r\n",
        "39 = keep left (mandatory)\r\n",
        "\r\n",
        "40 = roundabout (mandatory)\r\n",
        "\r\n",
        "41 = restriction ends (overtaking) (other)\r\n",
        "\r\n",
        "42 = restriction ends (overtaking (trucks)) \r\n",
        "(other)\r\n",
        "\r\n",
        "4. Create file obj.data in the folder darknet-master->data, containing the given text (replace classes = number of objects)\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "classes = 43\r\n",
        "train = data/train.txt\r\n",
        "valid = data/test.txt\r\n",
        "names = data/obj.names\r\n",
        "backup = backup/\r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "5. Create a folder in the directory darknet-master->data named obj now inside this obj folder put all your images and the respective txt files you got from labeling the dataset (**ONLY NECESSARY FOR THE TRAINING, NOT FOT THE DETECTION**)\r\n",
        "\r\n",
        "6. Now we have to create a train.txt file.This file directs to all training images as shown in the below picture.The easiest way to achieve this is store all images in a folder in computer open command prompt navigate to the folder using ‘cd’ and type command ‘ls’ if in linux and ‘dir’ if in windows.This will display all image names copy that and paste in text file and add ‘data/obj/train’ to each line for this Find and replace option could be used.The train.txt file is stored in the darknet-master->data folder. (**ONLY NECESSARY FOR THE TRAINING, NOT FOT THE DETECTION**)\r\n",
        "\r\n",
        "```\r\n",
        "data/obj/Train/00179.ppm\r\n",
        "data/obj/Train/00382.ppm\r\n",
        "data/obj/Train/00353.ppm\r\n",
        "data/obj/Train/00265.ppm\r\n",
        "..\r\n",
        "..\r\n",
        "```\r\n",
        "**The same thing must be done for the validation set.**\r\n",
        "\r\n",
        "7. In the darknet-master folder open Makefile in wordpad and change GPU=1,CUDNN=1,OPENCV=1 as shown in the following picture.This is done to make the training on GPU.\r\n",
        "\r\n",
        "```\r\n",
        "GPU=1\r\n",
        "CUDNN=1\r\n",
        "CUDNN_HALF=0\r\n",
        "OPENCV=1\r\n",
        "AVX=0\r\n",
        "OPENMP=0\r\n",
        "LIBSO=0\r\n",
        "ZED_CAMERA=0 # ZED SDK 3.0 and above\r\n",
        "ZED_CAMERA_v2_8=0 # ZED SDK 2.X\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCPJu6Fjabjz"
      },
      "source": [
        "## Training on the GTSDB Dataset and Detecting Signs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17V5c5YdDRlY"
      },
      "source": [
        "Now the modifications have been made, the training can start."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag_kGiy9DL_M"
      },
      "source": [
        "./darknet detector train data/obj.data cfg/yolo-obj.cfg yolov4.conv.137 -dont_show -map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCXOeBCMEDoP"
      },
      "source": [
        "Now that the network is trained it is ready to be used for detection.\r\n",
        "\r\n",
        "let's take 'data/obj/Test/00601.ppm' as an example here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_c6VL6abxBj"
      },
      "source": [
        "# This code has to be executed one time only\r\n",
        "#coco.names is hardcoded somewhere in the detector\r\n",
        "%cp data/obj.names data/coco.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikq-L41fEHVz"
      },
      "source": [
        "./darknet detect cfg/yolo-obj.cfg backup/custom-yolov4-detector_best.weights data/obj/Test/00601.ppm -dont-show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-GRVFnOal94"
      },
      "source": [
        "To be able to see the results of the detection use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOakJPzhavu1"
      },
      "source": [
        "#define utility function\r\n",
        "def imShow(path):\r\n",
        "  import cv2\r\n",
        "  import matplotlib.pyplot as plt\r\n",
        "  %matplotlib inline\r\n",
        "\r\n",
        "  image = cv2.imread(path)\r\n",
        "  height, width = image.shape[:2]\r\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\r\n",
        "\r\n",
        "  fig = plt.gcf()\r\n",
        "  fig.set_size_inches(18, 10)\r\n",
        "  plt.axis(\"off\")\r\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\r\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piKjG_Xia0xS"
      },
      "source": [
        "./darknet detect cfg/yolo-obj.cfg backup/custom-yolov4-detector_best.weights data/obj/Test/00601.ppm -dont-show\r\n",
        "imShow('predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlSh9TlpbCDn"
      },
      "source": [
        "## Implementing in the hardware"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQWUMiD7bJYd"
      },
      "source": [
        "To implement the yolov4 model in the hardware, some of the steps above are not necessary. The dataset (image and annotations) shouldnt be uploaded into the machine, since we are using the best weights for detection. The text files containing the images of the training and validation dataset aren't necessary for the detection either."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JgnpxOZ_Dcn"
      },
      "source": [
        "Additional sources:\r\n",
        "https://github.com/AlexeyAB/darknet\r\n",
        "https://colab.research.google.com/drive/1mzL6WyY9BRx4xX476eQdhKDnd_eixBlG#scrollTo=x-_E3O5Mf4Mf\r\n",
        "https://benchmark.ini.rub.de/\r\n",
        "https://medium.com/ai-world/how-to-train-yolov4-for-custom-objects-detection-in-google-colab-1e934b8ef685"
      ]
    }
  ]
}